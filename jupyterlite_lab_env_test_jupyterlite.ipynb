{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChoudharyImran/Lab-5-Exploring-the-Dataset/blob/main/jupyterlite_lab_env_test_jupyterlite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dea9f617-29f4-4555-ad11-e04cd8b7c2da"
      },
      "source": [
        "<p style=\"text-align:center\">\n",
        "    <a href=\"https://skills.network\" target=\"_blank\">\n",
        "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
        "    </a>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "511bc528-6453-4d18-8b5f-c2a15c73abd8"
      },
      "source": [
        "# Hands-on Lab: Considerations for Data Professionals using GenAI\n",
        "\n",
        "**Estimated time needed:** 45 minutes\n",
        "\n",
        "## Overview  \n",
        "\n",
        "In this lab, you will assess and reinforce your understanding of key principles related to the ethical deployment of generative AI, specifically focusing on transparency, fairness, responsibility, accountability, and reliability.  \n",
        "\n",
        "You will be presented with scenarios, and you are expected to provide a solution for the question based on the scenario. To help you with the solutions, a hint is provided for each exercise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "895568b0-1dc2-420f-ba4e-259e825d8955"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "255fc3eb-8568-4ab9-ab5b-977a499159dc"
      },
      "source": [
        "## Learning Objectives\n",
        "\n",
        "After completing this lab, you will be able to:\n",
        "\n",
        " - Maintain transparency and fairness in your AI system\n",
        "\n",
        " - Ensure accountability in the deployment of AI chatbot\n",
        "\n",
        " - Enhance the reliability of your AI model to ensure accurate product descriptions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86228637-b8b8-4c3f-be48-59881b53f5b9"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e86cd5ae-2c81-48a3-8247-f0fb27f00d0b"
      },
      "source": [
        "## Exercise 1:  \n",
        "\n",
        "You are developing a generative AI system that creates personalized content recommendations for users. The system seems to consistently recommend content that aligns with certain cultural and demographic biases.  \n",
        "\n",
        "Users from diverse backgrounds are expressing concern about the lack of transparency and fairness in the recommendations.  \n",
        "\n",
        "How do you maintain transparency and fairness in your AI system?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bec1a3fd-6648-436e-9e36-3426b1b33975"
      },
      "source": [
        "\n",
        "1. Conduct a Thorough Bias Assessment and Measurement\n",
        "The first step is to diagnose and quantify the problem. You cannot fix biases you cannot measure.\n",
        "\n",
        "Identify Biases: Conduct a comprehensive audit of your training data and model algorithms to identify where and how cultural and demographic biases are present.\n",
        "\n",
        "Quantify with Specialized Tools: Use established frameworks to get objective measurements. As you noted, powerful open-source toolkits are ideal for this:\n",
        "\n",
        "AI Fairness 360 (AIF360): Now a project under the Linux Foundation AI & Data, this IBM-developed toolkit is excellent for analyzing datasets and models. It allows you to use metrics like statistical parity (ensuring all groups receive recommendations at similar rates) and equalized odds to pinpoint unfairness.\n",
        "\n",
        "Holistic AI Library: This library is another powerful option for analyzing data across multiple dimensions, providing clear visualizations that help the development team understand the nature and extent of the bias.\n",
        "\n",
        "2. Enhance and Diversify Training Data\n",
        "The output of an AI system is a reflection of its training data. Therefore, enhancing the data is a foundational step.\n",
        "\n",
        "Source Diverse Data: Based on the results of your bias assessment, actively work to enhance the diversity of your training data. This means including a broader range of cultural, demographic, and behavioral data that is truly representative of your entire user base, not just the majority.\n",
        "\n",
        "Continuous Data Curation: This is not a one-time fix. Data diversity must be continuously monitored and improved as your user base grows and evolves.\n",
        "\n",
        "3. Implement Explainability and Transparency Features\n",
        "For users to trust the system, they must be able to understand it. Transparency demystifies the AI and empowers the user.\n",
        "\n",
        "\"Why am I seeing this?\" Feature: Implement explainability features that give users clear, concise insights into why a specific recommendation was made. This could show key influencing factors such as:\n",
        "\n",
        "\"Because you showed interest in [Related Topic/Creator]\"\n",
        "\n",
        "\"Trending in [Your Region]\"\n",
        "\n",
        "\"Based on content you recently viewed\"\n",
        "\n",
        "This transparency builds immediate trust and gives users a sense of control.\n",
        "\n",
        "4. Establish a Continuous User Feedback Loop\n",
        "The most accurate measure of fairness comes from the users themselves. An active feedback loop is essential for long-term improvement.\n",
        "\n",
        "Direct Reporting: Create a simple, accessible mechanism for users to report recommendations they find biased, irrelevant, or inappropriate.\n",
        "\n",
        "Iterative Improvement: Regularly collect, analyze, and categorize this user feedback. Use these qualitative insights as a crucial signal to guide the iterative retraining and refinement of your algorithms, ensuring the system's fairness improves over time.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "688065e5-16d5-4265-b4d2-e119002b504d"
      },
      "source": [
        "<details><summary>Click here for hint</summary>\n",
        "Consider steps like conducting a bias assessment, enhancing diversity in training data, implementing explainability features, and establishing a user feedback loop to ensure fairness and transparency in your AI system.\n",
        "</details>\n",
        "\n",
        "<details><summary>Click here for sample solution</summary>\n",
        "To address this issue, you could implement the following steps:\n",
        "\n",
        "1. Conduct a thorough bias assessment to identify and understand the biases present in the training data and algorithms.\n",
        "2. Use specialized tools or metrics to measure and quantify biases in content recommendations.\n",
        "3. Enhance the diversity of your training data by including a broader range of cultural, demographic, and user behavior data.\n",
        "4. Ensure that the training data reflects the diversity of your user base to reduce biases.\n",
        "5. Implement explainability features to provide users with insights into why specific recommendations are made.\n",
        "6. Offer transparency by showing the key factors and attributes influencing the recommendations.\n",
        "7. Establish a user feedback loop where users can report biased recommendations or provide feedback on content relevance.\n",
        "8. Regularly analyze this feedback to iteratively improve the system's fairness.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "517b987e-fa48-4206-8094-9543df6e46ba"
      },
      "source": [
        ">**Additional Information**\n",
        "\n",
        ">Some specialized tools that can be used to measure and quantify biases:\n",
        "\n",
        ">Holistic AI Library: This open-source library offers a range of metrics and mitigation strategies for various AI tasks, including content recommendation. It analyzes data for bias across different dimensions and provides visualizations for clear understanding.\n",
        "\n",
        ">Fairness 360: IBM&#39;s Fairness 360 toolkit provides various tools like Aequitas and What-If Tool to analyze bias in data sets, models, and decision-making processes. It offers metrics like statistical parity, differential odds ratio, and counterfactual fairness. IBM moved AI Fairness 360 to LF AI in July 2020.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9e98c0b7-7c9d-4896-90ca-25939d9326f7"
      },
      "source": [
        "## Exercise 2  \n",
        "\n",
        "Your company has deployed a chatbot powered by generative AI to interact with customers. The chatbot occasionally generates responses that are inappropriate or offensive, leading to customer dissatisfaction. As the AI developer, how do you take responsibility for these incidents and ensure accountability in the deployment of the AI chatbot?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43b2972c-1235-4b47-8a90-3ad65e3ad293"
      },
      "source": [
        "Of course. Here is a rephrased version of the text. This content is free for you to use, modify, and distribute as you wish.\n",
        "\n",
        "***\n",
        "\n",
        "### **Phase 1: Immediate Action and Mitigation** üöë\n",
        "\n",
        "The priority is to take swift action to manage and minimize the impact of the error.\n",
        "\n",
        "* **Public Acknowledgment:** Proactively communicate with any affected parties. Take ownership of the chatbot's failure, offer a sincere apology, and provide assurance that corrective measures are underway.\n",
        "* **Isolate the Issue:** Activate a system to rapidly flag and remove harmful responses. This can be achieved through automated content filters or a manual override function for a support team.\n",
        "\n",
        "### **Phase 2: Root Cause Investigation** üîç\n",
        "\n",
        "With the immediate problem contained, the focus shifts to a deep dive into the underlying cause.\n",
        "\n",
        "* **Incident Analysis:** Perform a detailed review of the inappropriate outputs to identify common themes or triggers. Investigate if the failures are linked to specific subjects or user inputs.\n",
        "* **Pinpoint the Origin:** Determine if the root cause is flawed training data, inherent model limitations, or insufficient safety protocols.\n",
        "\n",
        "### **Phase 3: Technical Solutions and Safeguards** üõ†Ô∏è\n",
        "\n",
        "Using insights from the investigation, implement robust technical fixes and preventative measures.\n",
        "\n",
        "* **Model Refinement:** Adjust the model by updating its training data. Include explicit examples of undesirable interactions and reinforce the correct, safe conversational paths.\n",
        "* **Real-Time Monitoring:** Deploy automated systems designed to continuously scan for and flag potentially inappropriate content in real-time before it is displayed to a user.\n",
        "* **Human Escalation Protocol:** Develop a process where conversations involving sensitive topics or low AI confidence are automatically routed to a human agent for management.\n",
        "\n",
        "### **Phase 4: Long-Term Governance and Transparency** üì¢\n",
        "\n",
        "Accountability is demonstrated through transparent communication and a lasting commitment to ethical operation.\n",
        "\n",
        "* **Transparent Reporting:** Clearly report on the actions taken to resolve the issue to all stakeholders, including customers and internal teams. Focus on the solution and the steps taken to prevent recurrence.\n",
        "* **Commitment to Responsible AI:** Position the incident as a learning opportunity within a broader commitment to continuous improvement. Reinforce that the responsible deployment of AI technology is an ongoing process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c2c549e-c648-4c72-9b4e-93526c821c3d"
      },
      "source": [
        "<details><summary>Click here for hint</summary>\n",
        "To address responsibility and accountability, analyze errors, respond swiftly, continuously monitor for inappropriate responses, and communicate openly with stakeholders about corrective actions taken to improve the chatbot&#39;s behavior.\n",
        "</details>\n",
        "\n",
        "<details><summary>Click here for sample solution</summary>\n",
        "Addressing responsibility and accountability in this scenario involves the following steps:\n",
        "\n",
        "1. Conduct a detailed analysis of the inappropriate responses to identify patterns and root causes.\n",
        "2. Determine whether the issues stem from biased training data, algorithmic limitations, or other factors.\n",
        "3. Implement a mechanism to quickly identify and rectify inappropriate responses by updating the chatbot&#39;s training data or fine-tuning the model.\n",
        "4. Communicate openly with affected customers, acknowledge the issue, and assure them of prompt corrective actions.\n",
        "5. Set up continuous monitoring systems to detect and flag inappropriate responses in real-time.\n",
        "6. Implement alerts or human-in-the-loop mechanisms to intervene when the system generates potentially harmful content.\n",
        "7. Clearly communicate the steps taken to address the issue to both internal stakeholders and customers.\n",
        "8. Emphasize the commitment to continuous improvement and the responsible use of AI technology.\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37204c8c-2392-4eed-90fd-836d4ac5ccfd"
      },
      "source": [
        "## Exercise 3:\n",
        "\n",
        "Your company has developed a generative AI model that autonomously generates product descriptions for an e-commerce platform. However, users have reported instances where the generated descriptions contain inaccurate information, leading to customer confusion and dissatisfaction. How do you enhance the reliability of your AI model to ensure accurate product descriptions?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2687664a-b14b-4294-bfa0-4de187f7360f"
      },
      "source": [
        "A Framework for Reliable AI-Generated Content\n",
        "To ensure the AI produces dependable and accurate product descriptions, a systematic approach is essential. This involves focusing on the quality of the model's foundational knowledge, implementing strict quality control, and building a system designed for continuous learning.\n",
        "\n",
        "Consider the AI as a new product specialist. To ensure their success, you must provide them with authoritative information, review their work before it's public, and use customer interactions as opportunities for their ongoing development.\n",
        "\n",
        "Foundation: Authoritative and Clean Data üìö\n",
        "An AI's accuracy is a direct reflection of the data it's trained on.\n",
        "\n",
        "Establish a Source of Truth: Train the model using a curated, high-quality dataset specific to your product domain. Make official manufacturer specifications, technical data sheets, and verified supplier information the core of this dataset.\n",
        "\n",
        "Practice Data Hygiene: Instead of using raw data, ensure it is cleaned, structured, and well-organized. This helps the model accurately map features to products and significantly reduces the risk of generating factual errors or \"hallucinations.\"\n",
        "\n",
        "Verification: A Robust Quality Control Process ‚úÖ\n",
        "Establish a strong validation process to catch inaccuracies before they reach the customer.\n",
        "\n",
        "Develop a Benchmark Dataset: Create a comprehensive \"golden set\" of ideal, fact-checked product descriptions. This benchmark is used to quantitatively measure the AI's accuracy and track its performance over time across a diverse range of products.\n",
        "\n",
        "Implement Multi-Layered Validation: Combine automated checks for factual consistency (e.g., matching numerical specs) with a final review by human product experts. This hybrid approach ensures both scalability and high-fidelity accuracy.\n",
        "\n",
        "Evolution: Continuous Model Improvement üîÑ\n",
        "The product catalog is dynamic, and the AI model must be as well.\n",
        "\n",
        "Maintain a Dynamic Training Cycle: Move away from a \"train-once\" mindset. Implement a regular schedule for retraining the model with the most current product data, ensuring it stays synchronized with your inventory and any updates to product information.\n",
        "\n",
        "Synchronize with the Product Lifecycle: This iterative approach ensures the model can adapt to new product releases, version updates, and other changes, preventing the generation of outdated content.\n",
        "\n",
        "Refinement: Leveraging Customer Feedback üó£Ô∏è\n",
        "Your customers provide an invaluable resource for identifying and correcting errors.\n",
        "\n",
        "Create Frictionless Reporting: Integrate a simple and obvious way for users to flag descriptions they believe are inaccurate.\n",
        "\n",
        "Convert Feedback into Corrections: Systematically collect and process this user-generated feedback. Use these corrections as a high-value dataset for the targeted fine-tuning of the model, creating a powerful loop where the AI learns directly from its real-world mistakes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a1db187-f475-45ac-9063-68a07ee34189"
      },
      "source": [
        "<details><summary>Click here for hint</summary>\n",
        "To improve reliability, focus on quality assurance testing, use domain-specific training data, adopt an iterative model training approach, and integrate user feedback to iteratively correct errors and enhance the accuracy of the AI-generated product descriptions.\n",
        "</details>\n",
        "\n",
        "<details><summary>Click here for sample solution</summary>\n",
        "To improve the reliability of the AI model in generating product descriptions, consider the following actions:\n",
        "\n",
        "1. Implement rigorous quality assurance testing to evaluate the accuracy of the generated product descriptions.\n",
        "2. Create a comprehensive testing data set that covers a wide range of products and scenarios to identify and address inaccuracies.\n",
        "3. Ensure that the AI model is trained on a diverse and extensive data set specific to the e-commerce domain.\n",
        "4. Include product information from reputable sources to enhance the model's understanding of accurate product details.\n",
        "5. Implement an iterative training approach to continuously update and improve the model based on user feedback and evolving product data.\n",
        "6. Regularly retrain the model to adapt to changes in the product catalog and user preferences.\n",
        "7. Encourage users to provide feedback on inaccurate product descriptions.\n",
        "8. Use this feedback to fine-tune the model, correct errors, and improve the overall reliability of the AI-generated content.  \n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed298850-7e74-480a-87c3-5ecb045268f8"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee49f112-cc18-4093-84bf-25333abb70e8"
      },
      "source": [
        "# Congratulations! You have completed the lab\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52ca71ac-a3d4-4cc8-bb2a-a02fc6eefa25"
      },
      "source": [
        "## Authors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef210e91-535e-473e-bff1-5a3f6d1bc073"
      },
      "source": [
        "[Dr. Pooja](https://www.linkedin.com/in/p-b28802262/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fd673ed-6639-41c5-b8df-683d8f8d5b2d"
      },
      "source": [
        "### Other Contributors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db695ad4-5b00-413e-ae7e-57d0d31ea896"
      },
      "source": [
        "[Abhishek Gagneja](https://www.linkedin.com/in/abhishek-gagneja-23051987/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "137dd1be-1b29-4fa6-979e-b33d4b535019"
      },
      "source": [
        "<!--## Change Log--!>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f13953ea-52dd-4f90-8354-439dc639a8c1"
      },
      "source": [
        "<!--|Date (YYYY-MM-DD)|Version|Changed By|Change Description|\n",
        "|-|-|-|-|\n",
        "|2023-12-14|0.1|Abhishek Gagneja|Initial Draft created| --!>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f92545f-1a12-4fc3-9e2b-0210cdb2001e"
      },
      "source": [
        "## Copyright ¬© IBM Corporation. All rights reserved.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10b352ee-f2cb-457f-97a6-def6d8944f64"
      },
      "outputs": [],
      "source": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "prev_pub_hash": "9e54548042cc959abb34bd633a9f51784fd2555c0dc1ae36f4d6f1c95b8c4f14",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}